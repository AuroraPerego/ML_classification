{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T08:58:30.726214Z",
     "start_time": "2020-04-02T08:58:26.090270Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mpl.rcParams['figure.figsize'] = (6,6)\n",
    "# mpl.rcParams['figure.dpi'] = 100\n",
    "# mpl.rcParams[\"image.origin\"] = 'lower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T08:58:41.519395Z",
     "start_time": "2020-04-02T08:58:41.512526Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"base_dir\":        \"/eos/home-d/dmapelli/public/latino/\",\n",
    "    \"plot_config\":     \"Full2018v6s5\",\n",
    "    \"cut\":             \"res_sig_mjjincl\",\n",
    "    \"model_version\":   \"v68\",\n",
    "    #\"model_tag\":       \"boost_5vars_v0\",\n",
    "    \"samples_version\": \"v10\",\n",
    "    \"cols\": ['mjj_vbs',\n",
    "             'vbs_0_pt',\n",
    "             'vbs_1_pt', \n",
    "             'deltaeta_vbs',\n",
    "             'Lepton_eta',\n",
    "             'Zlep', \n",
    "             ]\n",
    "# A_ww\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T08:58:42.661453Z",
     "start_time": "2020-04-02T08:58:42.650972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(config[\"cols\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.python\n",
    "# config examples\n",
    "\"cut\":             \"boos_sig_mjjincl\",\n",
    "\"cut\":             \"res_sig_mjjincl\",\n",
    "\"model_tag\":       \"res_4depth_v0\",\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T08:58:52.034645Z",
     "start_time": "2020-04-02T08:58:51.583082Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "config_base_dir = os.path.join(config[\"base_dir\"], config[\"plot_config\"])\n",
    "\n",
    "# create the model directory\n",
    "model_dir   = os.path.join(config_base_dir, config[\"cut\"] , \"models\",  config[\"model_version\"])\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# load numpy\n",
    "samples_dir = os.path.join(config_base_dir, config[\"cut\"] , \"samples\", config[\"samples_version\"])\n",
    "import pickle\n",
    "signal = pickle.load(open(os.path.join(samples_dir, \"for_training/signal_balanced.pkl\"),     \"rb\"))\n",
    "bkg    = pickle.load(open(os.path.join(samples_dir, \"for_training/background_balanced.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples preparation for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using \n",
    "## source /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/setup.sh\n",
    "#!pip3 install --user imbalanced-learn==0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T09:00:36.518748Z",
     "start_time": "2020-04-02T09:00:36.511987Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from imblearn.keras import balanced_batch_generator\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:17:31.734886Z",
     "start_time": "2020-01-27T10:17:31.723341Z"
    }
   },
   "outputs": [],
   "source": [
    "## instead of reading the variables from file,\n",
    "## we now set the variables here, and then dump them\n",
    "# import yaml\n",
    "# yaml_vars = yaml.safe_load(open(os.path.join(model_dir, \"variables.yml\")))\n",
    "# print(\"yaml: \", type(yaml_vars), len(yaml_vars))\n",
    "# cols = yaml_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:23.689119Z",
     "start_time": "2020-01-27T10:43:23.381391Z"
    }
   },
   "outputs": [],
   "source": [
    "X_sig = signal[config[\"cols\"]].values\n",
    "X_bkg = bkg[config[\"cols\"]].values\n",
    "\n",
    "Y_sig = np.ones(len(X_sig))\n",
    "\n",
    "bkg.cat = bkg.sample_name\n",
    "bkg.cat = []\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "\n",
    "enc.fit([\"Wjets\", \"top\", \"DY\", \"VBS\", \"VV\"])\n",
    "\n",
    "\n",
    "Y_bkg = np.zeros(len(X_bkg))\n",
    "W_sig = (signal[\"weight_norm\"]).values\n",
    "W_bkg = (bkg[\"weight_norm\"]).values\n",
    "Wnn_sig = (signal[\"weight_\"]).values\n",
    "Wnn_bkg = (bkg[\"weight_\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:27.283132Z",
     "start_time": "2020-01-27T10:43:27.081356Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.vstack([X_sig, X_bkg])\n",
    "Y = np.hstack([Y_sig, Y_bkg])\n",
    "W = np.hstack([W_sig, W_bkg])\n",
    "Wnn = np.hstack([Wnn_sig, Wnn_bkg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:32.170798Z",
     "start_time": "2020-01-27T10:43:30.694579Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pickle.dump(scaler, open(f\"{model_dir}/scaler_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T08:46:36.955475Z",
     "start_time": "2020-01-27T08:46:34.860619Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i = 2\n",
    "# print(cols[i])\n",
    "# fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10,5), dpi=100)\n",
    "# ax1.hist(X[:,i], bins=50)\n",
    "# ax1.set_yscale(\"log\")\n",
    "# ax2.hist(X_scaled[:,i], weights=W, bins=50)\n",
    "# plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:17:47.639149Z",
     "start_time": "2020-01-27T10:17:47.039479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD6CAYAAABNu5eFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAATXElEQVR4nO3df6zd9X3f8eerhDCahgWGYZ4NNZW8aQYtP7iyaJmqtEzDTdqZSWNytBWvQrKG2EalaavJH632hyX2z1QhDSaUZRgtDbPaZlgttGFuo24Lwb1kJGAIwwsMPHvYTbqFdBMZ1nt/nA/J6fW5936v7z3n+vrzfEhH53ve5/s553OOvn59P/fz/Z6vU1VIkvrwQ+vdAUnS7Bj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdGRT6ST6U5NeTfCPJy0l+PMlVSZ5O8mq7v3Js/fuTHE/ySpLbx+o3J3mhPfdgkkzjQ0mSJsuQ8/STHAT+Y1V9Jsn7gR8GPg18u6oeSLIfuLKqfinJDuDzwE7gLwD/AfiLVXU2yVHgPuArwJPAg1X11FLvffXVV9e2bdvO/xNKUoeee+65P6qqTQvr71uuYZIrgJ8E/h5AVX0P+F6S3cDH22oHgS8BvwTsBh6vqneA15IcB3YmeR24oqqeaa/7GHAHsGTob9u2jfn5+eU/oSTp+5L890n1IdM7PwacAf5Nkv+S5DNJPgBcW1WnANr9NW39LcCbY+1PtNqWtrywLkmakSGh/z7gY8DDVfVR4E+A/UusP2mevpaon/sCyb4k80nmz5w5M6CLkqQhhoT+CeBEVT3bHv86o53AW0k2A7T702PrXzfWfitwstW3Tqifo6oeqaq5qprbtOmcKSlJ0nlaNvSr6n8Cbyb5S610G/AScBjY22p7gSfa8mFgT5LLktwAbAeOtimgt5Pc0s7auWusjSRpBpY9kNv8Q+Bz7cydbwK/wGiHcSjJ3cAbwJ0AVXUsySFGO4Z3gXur6mx7nXuAR4HLGR3AXfIgriRpbQ06ZXM9zc3NlWfvSNLKJHmuquYW1v1FriR1xNCXpI4Y+pLUkaEHcru2bf9vf3/59Qc+uY49kaTVcaQvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6og/zlohf6glaSNzpC9JHTH0Jakjhr4kdcTQl6SOXNQHcj3oKkl/miN9SeqIoS9JHTH0Jakjhr4kdcTQl6SOXNRn76zG+Jk/knSxcKQvSR0x9CWpI4a+JHVkUOgneT3JC0meTzLfalcleTrJq+3+yrH1709yPMkrSW4fq9/cXud4kgeTZO0/kiRpMSsZ6f9UVX2kquba4/3AkaraDhxpj0myA9gD3AjsAh5Kcklr8zCwD9jebrtW/xEkSUOtZnpnN3CwLR8E7hirP15V71TVa8BxYGeSzcAVVfVMVRXw2FgbSdIMDA39Ar6Y5Lkk+1rt2qo6BdDur2n1LcCbY21PtNqWtrywLkmakaHn6d9aVSeTXAM8neQbS6w7aZ6+lqif+wKjHcs+gOuvv35gFyVJyxk00q+qk+3+NPAFYCfwVpuyod2fbqufAK4ba74VONnqWyfUJ73fI1U1V1VzmzZtGv5pJElLWjb0k3wgyQffWwb+OvAicBjY21bbCzzRlg8De5JcluQGRgdsj7YpoLeT3NLO2rlrrI0kaQaGTO9cC3yhnV35PuDXqup3kvwhcCjJ3cAbwJ0AVXUsySHgJeBd4N6qOtte6x7gUeBy4Kl2kyTNyLKhX1XfBD48of4t4LZF2hwADkyozwM3rbybkqS14AXXVsH/jlHSRuNlGCSpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BH/Y/SLmP9xu6SFHOlLUkcc6a8RR9WSNgJDv0PuoKR+Ob0jSR0x9CWpI4Ond5JcAswD/6OqfjbJVcC/A7YBrwN/u6r+uK17P3A3cBb4R1X1u61+M/AocDnwJHBfVdVafRgtbnxKR1K/VjLSvw94eezxfuBIVW0HjrTHJNkB7AFuBHYBD7UdBsDDwD5ge7vtWlXvJUkrMij0k2wFPgl8Zqy8GzjYlg8Cd4zVH6+qd6rqNeA4sDPJZuCKqnqmje4fG2ujVdi2/7e/f5OkpQyd3vlV4J8CHxyrXVtVpwCq6lSSa1p9C/CVsfVOtNr/a8sL61pDKw1+z+SR+rLsSD/JzwKnq+q5ga+ZCbVaoj7pPfclmU8yf+bMmYFvK0lazpDpnVuBv5HkdeBx4KeT/FvgrTZlQ7s/3dY/AVw31n4rcLLVt06on6OqHqmquaqa27Rp0wo+jiRpKcuGflXdX1Vbq2obowO0v1dVfxc4DOxtq+0FnmjLh4E9SS5LcgOjA7ZH21TQ20luSRLgrrE2kqQZWM0vch8ADiW5G3gDuBOgqo4lOQS8BLwL3FtVZ1ube/jBKZtPtZvOgwdtJZ2PFYV+VX0J+FJb/hZw2yLrHQAOTKjPAzettJOSpLXhtXfGrNXoeaOeEbNR+y1pOC/DIEkdMfQlqSOGviR1xNCXpI54IHfKNurB0Y3ab0lLM/RnyCCVtN6c3pGkjhj6ktQRQ1+SOuKc/gbi9XYkrZahv04WBrgHdiXNQjeh75kzktRR6G9UTulIWkuGvpblX0nSxcOzdySpI470L0BO6UiaFkf6ktQRR/oXCEf3kmbBkb4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKdsakW8JIO0sTnSl6SOLBv6Sf5MkqNJvpbkWJJ/1upXJXk6yavt/sqxNvcnOZ7klSS3j9VvTvJCe+7BJJnOx5IkTTJkpP8O8NNV9WHgI8CuJLcA+4EjVbUdONIek2QHsAe4EdgFPJTkkvZaDwP7gO3ttmsNP4skaRnLhn6NfLc9vLTdCtgNHGz1g8AdbXk38HhVvVNVrwHHgZ1JNgNXVNUzVVXAY2NtJEkzMGhOP8klSZ4HTgNPV9WzwLVVdQqg3V/TVt8CvDnW/ESrbWnLC+uT3m9fkvkk82fOnFnJ55EkLWFQ6FfV2ar6CLCV0aj9piVWnzRPX0vUJ73fI1U1V1VzmzZtGtJFSdIAKzp7p6r+F/AlRnPxb7UpG9r96bbaCeC6sWZbgZOtvnVCXZI0I0PO3tmU5ENt+XLgrwHfAA4De9tqe4En2vJhYE+Sy5LcwOiA7dE2BfR2klvaWTt3jbWRJM3AkB9nbQYOtjNwfgg4VFW/leQZ4FCSu4E3gDsBqupYkkPAS8C7wL1Vdba91j3Ao8DlwFPtJkmakWVDv6q+Dnx0Qv1bwG2LtDkAHJhQnweWOh4gSZoiL8Og8+YlGaSNx8swSFJHDH1J6oihL0kd6X5Of3xeWpIudo70Jakjhr4kdcTQl6SOGPqS1BFDX5I60v3ZO1ob/jpX2hgc6UtSRwx9SeqIoS9JHTH0JakjXR7I9dIL0+VBXenC5Uhfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOdHmevmbHc/alC4sjfUnqiKEvSR1ZNvSTXJfk95O8nORYkvta/aokTyd5td1fOdbm/iTHk7yS5Pax+s1JXmjPPZgk0/lYkqRJhoz03wX+cVX9ZeAW4N4kO4D9wJGq2g4caY9pz+0BbgR2AQ8luaS91sPAPmB7u+1aw88iSVrGsqFfVaeq6qtt+W3gZWALsBs42FY7CNzRlncDj1fVO1X1GnAc2JlkM3BFVT1TVQU8NtZGkjQDK5rTT7IN+CjwLHBtVZ2C0Y4BuKattgV4c6zZiVbb0pYX1iVJMzI49JP8CPAbwC9W1XeWWnVCrZaoT3qvfUnmk8yfOXNmaBclScsYFPpJLmUU+J+rqt9s5bfalA3t/nSrnwCuG2u+FTjZ6lsn1M9RVY9U1VxVzW3atGnoZ5EkLWPI2TsB/jXwclX9i7GnDgN72/Je4Imx+p4klyW5gdEB26NtCujtJLe017xrrI0kaQaG/CL3VuDngReSPN9qnwYeAA4luRt4A7gToKqOJTkEvMTozJ97q+psa3cP8ChwOfBUu6kT/jpXWn/Lhn5V/Scmz8cD3LZImwPAgQn1eeCmlXRQkrR2/EWuJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oj/c5bWhefsS+vDkb4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR3xPH2tO8/Zl2bHkb4kdcTQl6SOOL2jC8r4VA843SOtNUf6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOesqkLmr/WldaWI31J6oihL0kdWTb0k3w2yekkL47VrkrydJJX2/2VY8/dn+R4kleS3D5WvznJC+25B5Nk7T+OJGkpQ0b6jwK7FtT2A0eqajtwpD0myQ5gD3Bja/NQkktam4eBfcD2dlv4mpKkKVs29KvqD4BvLyjvBg625YPAHWP1x6vqnap6DTgO7EyyGbiiqp6pqgIeG2sjSZqR853Tv7aqTgG0+2tafQvw5th6J1ptS1teWJckzdBan7I5aZ6+lqhPfpFkH6OpIK6//vq16Zk2PE/flFbvfEP/rSSbq+pUm7o53eongOvG1tsKnGz1rRPqE1XVI8AjAHNzc4vuHNQvdwDS+Tnf6Z3DwN62vBd4Yqy+J8llSW5gdMD2aJsCejvJLe2snbvG2kiSZmTZkX6SzwMfB65OcgL4FeAB4FCSu4E3gDsBqupYkkPAS8C7wL1Vdba91D2MzgS6HHiq3SRJM7Rs6FfVpxZ56rZF1j8AHJhQnwduWlHvJElryl/kSlJHvOCaNjwP6krDOdKXpI4Y+pLUEUNfkjrinL4uKs7vS0sz9HXRcgcgncvQVxfcAUgjhr664w5APfNAriR1xJG+1Iz/BTBu2n8N+JeHZsnQV9cWC/rVvM5iwT3kvdwBaNoMfWkZq/kLYDU7laFth+xk3IHoPYa+tMbW6q+HtXy/Ieu4Y+iDoS+dp1mHu7QWDH1JgNNBvTD0JS1pvc5q0nQY+pLO4ZlGFy9DX9KquQPYOAx9SWvKM4UubIa+pJnzL4P1Y+hLWlceKJ4tQ1/SBWm1v4NwpzGZoS9JC1zM00+GvqSL0kr/UujlGkaGviSxdtcwWsz4DmM9dySGviTNwGI7jFkfyJ75/5yVZFeSV5IcT7J/1u8vST2baegnuQT4l8DPADuATyXZMcs+SFLPZj3S3wkcr6pvVtX3gMeB3TPugyR1a9ahvwV4c+zxiVaTJM3ArA/kZkKtzlkp2Qfsaw+/m+SV83y/q4E/Os+202S/VsZ+rYz9WpkLsl/556vu149OKs469E8A14093gqcXLhSVT0CPLLaN0syX1Vzq32dtWa/VsZ+rYz9Wpne+jXr6Z0/BLYnuSHJ+4E9wOEZ90GSujXTkX5VvZvkHwC/C1wCfLaqjs2yD5LUs5n/OKuqngSenNHbrXqKaErs18rYr5WxXyvTVb9Sdc5xVEnSRWrmv8iVJK2fDRn6y13KISMPtue/nuRjQ9tOuV9/p/Xn60m+nOTDY8+9nuSFJM8nmZ9xvz6e5H+3934+yS8PbTvlfv2TsT69mORskqvac9P8vj6b5HSSFxd5fr22r+X6tV7b13L9Wq/ta7l+rdf2dV2S30/ycpJjSe6bsM70trGq2lA3RgeA/xvwY8D7ga8BOxas8wngKUa/C7gFeHZo2yn36yeAK9vyz7zXr/b4deDqdfq+Pg781vm0nWa/Fqz/c8DvTfv7aq/9k8DHgBcXeX7m29fAfs18+xrYr5lvX0P6tY7b12bgY235g8B/nWWGbcSR/pBLOewGHquRrwAfSrJ5YNup9auqvlxVf9wefoXR7xSmbTWfeV2/rwU+BXx+jd57SVX1B8C3l1hlPbavZfu1TtvXkO9rMev6fS0wy+3rVFV9tS2/DbzMuVcmmNo2thFDf8ilHBZbZ5qXgVjpa9/NaE/+ngK+mOS5jH6RvFaG9uvHk3wtyVNJblxh22n2iyQ/DOwCfmOsPK3va4j12L5Walbb11Cz3r4GW8/tK8k24KPAswuemto2thGvpz/kUg6LrTPoMhDnafBrJ/kpRv8o/+pY+daqOpnkGuDpJN9oI5VZ9OurwI9W1XeTfAL498D2gW2n2a/3/Bzwn6tqfNQ2re9riPXYvgab8fY1xHpsXyuxLttXkh9htKP5xar6zsKnJzRZk21sI470h1zKYbF1Bl0GYor9IslfAT4D7K6qb71Xr6qT7f408AVGf8bNpF9V9Z2q+m5bfhK4NMnVQ9pOs19j9rDgT+8pfl9DrMf2Ncg6bF/LWqftayVmvn0luZRR4H+uqn5zwirT28amcaBimjdGf518E7iBHxzIuHHBOp/kTx8EOTq07ZT7dT1wHPiJBfUPAB8cW/4ysGuG/frz/OA3GzuBN9p3t67fV1vvzzKal/3ALL6vsffYxuIHJme+fQ3s18y3r4H9mvn2NaRf67V9tc/+GPCrS6wztW1sw03v1CKXckjy99vz/4rRL34/wegfwP8BfmGptjPs1y8Dfw54KAnAuzW6oNK1wBda7X3Ar1XV78ywX38LuCfJu8D/BfbUaAtb7+8L4G8CX6yqPxlrPrXvCyDJ5xmdcXJ1khPArwCXjvVr5tvXwH7NfPsa2K+Zb18D+wXrsH0BtwI/D7yQ5PlW+zSjnfbUtzF/kStJHdmIc/qSpPNk6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JH/D0iPvKjQb/HAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# _ = plt.hist(W, bins=100)\n",
    "_ = plt.hist(W, bins=100, range=(0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T08:50:38.324736Z",
     "start_time": "2020-01-21T08:50:38.320100Z"
    }
   },
   "source": [
    "##  Balancing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:36.951718Z",
     "start_time": "2020-01-27T10:43:36.191197Z"
    }
   },
   "outputs": [],
   "source": [
    "config[\"test_size\"] = 0.2\n",
    "#config[\"val_size\"]  = 0.5  ## test != val\n",
    "config[\"val_size\"]  = 0.0  ## test == val\n",
    "\n",
    "X_train, X_temp, y_train, y_temp, W_train, W_temp , Wnn_train, Wnn_temp = train_test_split(X_scaled, Y,  W, Wnn, test_size=config[\"test_size\"], random_state=42, stratify=Y)\n",
    "\n",
    "#X_val,   X_test, y_val,   y_test, W_val,   W_test = train_test_split(X_temp,   y_temp, W_temp, test_size=config[\"val_size\"]) ## test != val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:41.448774Z",
     "start_time": "2020-01-27T10:43:41.444471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   dataset:  (139993, 6)\n",
      "Test + Val dataset:  (34999, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training   dataset: \", X_train.shape)\n",
    "print(\"Test + Val dataset: \", X_temp.shape)\n",
    "#print(\"Testing    dataset: \", X_test.shape)\n",
    "#print(\"Validation dataset: \", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create generators to balance signal and background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:47.072964Z",
     "start_time": "2020-01-27T10:43:46.189735Z"
    }
   },
   "outputs": [],
   "source": [
    "config[\"batch_size\"] = 2048\n",
    "\n",
    "training_generator,   steps_per_epoch_train = balanced_batch_generator(X_train, y_train, W_train, batch_size=config[\"batch_size\"], sampler=RandomOverSampler())\n",
    "#validation_generator, steps_per_epoch_val   = balanced_batch_generator(X_val,   y_val,   W_val,   batch_size=config[\"batch_size\"], sampler=RandomOverSampler()) ## test != val\n",
    "validation_generator, steps_per_epoch_val   = balanced_batch_generator(X_temp,  y_temp,  W_temp,   batch_size=config[\"batch_size\"], sampler=RandomOverSampler()) ## test == val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T10:43:12.667494Z",
     "start_time": "2020-01-27T10:43:12.356313Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0310 23:06:01.353649 139772135913280 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0310 23:06:01.388996 139772135913280 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0310 23:06:01.394811 139772135913280 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0310 23:06:01.566759 139772135913280 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0310 23:06:01.606418 139772135913280 deprecation.py:506] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0310 23:06:01.850431 139772135913280 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0310 23:06:01.888750 139772135913280 deprecation_wrapper.py:119] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0310 23:06:01.898470 139772135913280 deprecation.py:323] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                350       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,351\n",
      "Trainable params: 3,151\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import local module that programmatically returns keras models\n",
    "import dnn_models\n",
    "\n",
    "model = dnn_models.get_model(config[\"model_tag\"], X_train.shape[1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import and configure the plot loss callback\n",
    "\n",
    "import dnn_plot_loss\n",
    "\n",
    "data = {\n",
    "    \"X_train\": X_train,\n",
    "    #\"X_test\" : X_test, ## test != val\n",
    "    \"X_val\" : X_temp, ## test == val\n",
    "    \"y_train\": y_train,\n",
    "    #\"y_test\" : y_test, ## test != val\n",
    "    \"y_val\" : y_temp, ## test == val\n",
    "    \"W_train\": W_train,\n",
    "    #\"W_test\" : W_test, ## test != val\n",
    "    \"W_val\": W_temp, ## test == val\n",
    "    \"Wnn_train\": Wnn_train,\n",
    "    #\"W_test\" : W_test, ## test != val\n",
    "    \"Wnn_val\": Wnn_temp, ## test == val\n",
    "}\n",
    "\n",
    "plot_losses = dnn_plot_loss.PlotLosses(model, data, batch_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T11:49:32.295591Z",
     "start_time": "2020-01-27T11:13:58.490544Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 2s 18ms/step - loss: 0.5765 - acc: 0.6316 - val_loss: 0.5497 - val_acc: 0.6413\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5547 - acc: 0.6429 - val_loss: 0.5479 - val_acc: 0.6438\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 1s 10ms/step - loss: 0.5508 - acc: 0.6469 - val_loss: 0.5444 - val_acc: 0.6456\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.5490 - acc: 0.6487 - val_loss: 0.5433 - val_acc: 0.6464\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.5485 - acc: 0.6508 - val_loss: 0.5428 - val_acc: 0.6483\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5472 - acc: 0.6517 - val_loss: 0.5428 - val_acc: 0.6484\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5467 - acc: 0.6519 - val_loss: 0.5441 - val_acc: 0.6489\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5453 - acc: 0.6534 - val_loss: 0.5443 - val_acc: 0.6475\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5454 - acc: 0.6533 - val_loss: 0.5428 - val_acc: 0.6491\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5446 - acc: 0.6534 - val_loss: 0.5433 - val_acc: 0.6499\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5448 - acc: 0.6543 - val_loss: 0.5435 - val_acc: 0.6498\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5439 - acc: 0.6546 - val_loss: 0.5441 - val_acc: 0.6485\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5437 - acc: 0.6537 - val_loss: 0.5421 - val_acc: 0.6504\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5434 - acc: 0.6537 - val_loss: 0.5441 - val_acc: 0.6502\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5434 - acc: 0.6537 - val_loss: 0.5426 - val_acc: 0.6519\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5430 - acc: 0.6540 - val_loss: 0.5425 - val_acc: 0.6508\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5422 - acc: 0.6543 - val_loss: 0.5418 - val_acc: 0.6502\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5428 - acc: 0.6539 - val_loss: 0.5419 - val_acc: 0.6507\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5424 - acc: 0.6552 - val_loss: 0.5421 - val_acc: 0.6492\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 1s 11ms/step - loss: 0.5430 - acc: 0.6536 - val_loss: 0.5425 - val_acc: 0.6497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TRAINING\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "config[\"epochs\"] = 30\n",
    "\n",
    "history = model.fit_generator(\n",
    "            training_generator, \n",
    "            epochs=config[\"epochs\"],\n",
    "            steps_per_epoch  = steps_per_epoch_train, \n",
    "            validation_data  = validation_generator, \n",
    "            validation_steps = steps_per_epoch_val,\n",
    "            callbacks=[plot_losses],\n",
    "            #callbacks = [], \n",
    "            )\n",
    "\n",
    "config[\"train_time\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.990073442459106"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"train_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-27T12:55:58.730850Z",
     "start_time": "2020-01-27T12:55:57.810345Z"
    }
   },
   "outputs": [],
   "source": [
    "## SAVE THE MODEL, ITS METADATA AND TRAINING INFORMATIONS\n",
    "\n",
    "# dump the variables list\n",
    "import yaml\n",
    "varfile = os.path.join(model_dir, \"variables.yml\")\n",
    "if os.path.isfile(varfile):\n",
    "    print(\"ACHTUNG! variables file already existing: old file renamed with '_old'\")\n",
    "    os.rename(varfile, varfile[:-4] + \"_old.yml\")\n",
    "with open(varfile, \"w\") as out_var_file:\n",
    "    out_var_file.write(yaml.dump(config[\"cols\"]))\n",
    "    \n",
    "# dump the config\n",
    "config[\"a__model_dir\"] = model_dir\n",
    "model_config_file = os.path.join(model_dir, \"model_config.yml\")\n",
    "if os.path.isfile(model_config_file):\n",
    "    print(\"ACHTUNG! model_config_file file already existing: old file renamed with '_old'\")\n",
    "    os.rename(model_config_file, model_config_file[:-4] + \"_old.yml\")\n",
    "with open(model_config_file, \"w\") as out_var_file:\n",
    "    out_var_file.write(yaml.dump(config))  \n",
    "\n",
    "# save figure with training summary\n",
    "plot_losses.save_figure( os.path.join(model_dir, \"model_train.png\") )\n",
    "\n",
    "# save keras model\n",
    "model.save( os.path.join(model_dir, \"model.h5\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0310 23:06:43.475929 139772135913280 deprecation.py:323] From <ipython-input-23-39c8d219d3f3>:53: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0310 23:06:43.477826 139772135913280 deprecation.py:323] From /cvmfs/sft.cern.ch/lcg/views/LCG_96python3/x86_64-centos7-gcc8-opt/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "## Export:\n",
    "## * keras model to tensorflow model\n",
    "## * tf metadata\n",
    "## * scaler\n",
    "\n",
    "args = {\n",
    "    \"dir\": model_dir,\n",
    "    \"input\": \"model.h5\",\n",
    "    \"output\": \"model.pb\",\n",
    "    \"tf_metadata\": \"tf_metadata.txt\",\n",
    "    \"input_scaler\": \"scaler_model.pkl\",\n",
    "    \"output_scaler\": \"scaler.txt\",\n",
    "}\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "# This line must be executed before loading Keras model.\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(args[\"dir\"], args[\"input\"]))\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        # Graph -> GraphDef ProtoBuf\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
    "                                                      output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(),\n",
    "                              output_names=[out.op.name for out in model.outputs])\n",
    "\n",
    "# Save to ./model/tf_model.pb\n",
    "tf.train.write_graph(frozen_graph, args[\"dir\"], args[\"output\"], as_text=False)\n",
    "\n",
    "## save tensorflow metadata\n",
    "with open(os.path.join(args[\"dir\"], args[\"tf_metadata\"]), \"w\") as f:\n",
    "    f.write(str(model.inputs[0].name) + \" \" + str(model.outputs[0].name) + \"\\n\")\n",
    "\n",
    "\n",
    "## Export \n",
    "## * tf tensor input name and output name\n",
    "## * scaler mean_ and scale_ (where scale_ = np.sqrt(var_)) for each variable\n",
    "##\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import yaml\n",
    "yaml_vars = yaml.safe_load(open(os.path.join(args[\"dir\"], \"variables.yml\"), \"r\"))\n",
    "\n",
    "scaler = pickle.load(open(os.path.join(args[\"dir\"], args[\"input_scaler\"]), 'rb'))\n",
    "with open(os.path.join(args[\"dir\"], args[\"output_scaler\"]), \"w\") as f:\n",
    "    for var, mean, scale in zip(yaml_vars, scaler.mean_, scaler.scale_):\n",
    "        f.write(var + \" \" + str(mean) + \" \" + str(scale) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieve graphs history\n",
    "## plot \n",
    "# n = 30\n",
    "# plt.hist(plot_losses.dnn_score_plot[n][0][1][:-1], bins=plot_losses.dnn_score_plot[n][0][1], weights=plot_losses.dnn_score_plot[n][0][0], histtype=\"step\")\n",
    "# plt.hist(plot_losses.dnn_score_plot[n][1][1][:-1], bins=plot_losses.dnn_score_plot[n][1][1], weights=plot_losses.dnn_score_plot[n][1][0], histtype=\"step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```.python\n",
    "# resolved\n",
    "    \"cols\": ['mjj_vbs', \n",
    "             'vbs_0_pt', \n",
    "             'vbs_1_pt', \n",
    "             'deltaeta_vbs',\n",
    "             'deltaphi_vbs', \n",
    "             'mjj_vjet', \n",
    "             'vjet_0_pt', \n",
    "             'vjet_1_pt', \n",
    "             'vjet_0_eta', \n",
    "             'vjet_1_eta', \n",
    "             'Lepton_pt', \n",
    "             'Lepton_eta', \n",
    "             'Lepton_flavour', \n",
    "             'PuppiMET', \n",
    "             'Zvjets_0', \n",
    "             'Zlep', \n",
    "             'Asym_vbs', \n",
    "             'Asym_vjet', \n",
    "             'A_ww', \n",
    "             'Mtw_lep', \n",
    "             'w_lep_pt', \n",
    "             'Mww', \n",
    "             'R_ww', \n",
    "             'R_mw', \n",
    "             'Centr_vbs', \n",
    "             'Centr_ww'\n",
    "         ]\n",
    "\n",
    "# boosted\n",
    "    \"cols\": ['mjj_vbs', \n",
    "             'vbs_0_pt', \n",
    "             'vbs_1_pt', \n",
    "             'deltaeta_vbs',\n",
    "             'deltaphi_vbs', \n",
    "             'mjj_vjet', \n",
    "             'vjet_0_pt', \n",
    "             'vjet_1_pt', \n",
    "             'vjet_0_eta', \n",
    "             'vjet_1_eta', \n",
    "             'Lepton_pt', \n",
    "             'Lepton_eta', \n",
    "             'Lepton_flavour', \n",
    "             'PuppiMET', \n",
    "             'Zvjets_0', \n",
    "             'Zlep', \n",
    "             'Asym_vbs', \n",
    "             'Asym_vjet', \n",
    "             'A_ww', \n",
    "             'Mtw_lep', \n",
    "             'w_lep_pt', \n",
    "             'Mww', \n",
    "             'R_ww', \n",
    "             'R_mw', \n",
    "             'Centr_vbs', \n",
    "             'Centr_ww'\n",
    "         ]\n",
    "\n",
    "         \n",
    "# OLD\n",
    "    \"cols\": ['mjj_vbs', 'deltaeta_vbs', \n",
    "            'mjj_vjet', \n",
    "            'Lepton_pt', 'Lepton_eta' ]\n",
    "    \"cols\": ['mjj_vbs', \n",
    "             'vbs_0_pt', 'vbs_1_pt', \n",
    "             'deltaeta_vbs', 'deltaphi_vbs', \n",
    "             'mjj_vjet', \n",
    "             'vjet_0_pt', 'vjet_1_pt', \n",
    "             'vjet_0_eta', 'vjet_1_eta', \n",
    "             'Lepton_pt', 'Lepton_eta', 'Lepton_flavour', \n",
    "         ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
